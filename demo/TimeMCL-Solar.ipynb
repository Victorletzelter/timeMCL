{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of TimeMCL for Solar dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains an example for training TimeMCL on the Solar dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create the conda virtual environment with the required packages with `cd tsExperiments ; bash setup-env.sh`. Then activate it before running the next cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training can be performed with the following commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import rootutils\n",
    "import torch \n",
    "rootutils.setup_root(search_from='.', indicator=\".project-root\", pythonpath=True)\n",
    "\n",
    "sys.path.append(os.path.dirname(os.environ[\"PROJECT_ROOT\"]))\n",
    "sys.path.append(os.path.join(os.environ[\"PROJECT_ROOT\"], \"tsExperiments\"))\n",
    "from tsExperiments.scripts_plot.plottimeMCL import plot_mcl\n",
    "from gluonts.dataset.repository import get_dataset\n",
    "from tsExperiments.models.project_models.tMCL.personnalized_evaluator import (\n",
    "    MultivariateEvaluator,\n",
    ")\n",
    "from gluonts.dataset.multivariate_grouper import MultivariateGrouper\n",
    "from tsExperiments.models.project_models.tMCL.personnalized_evaluator import MultivariateEvaluator\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from tsExperiments.models.project_models.tMCL.timeMCL_estimator import timeMCL_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"solar_nips\" \n",
    "\n",
    "dataset = get_dataset(dataset_name, regenerate=False)\n",
    "metadata = dataset.metadata\n",
    "\n",
    "datasets_params = {\n",
    "    \"exchange_rate_nips\": {\"num_feat_dynamic_real\": 4},\n",
    "    \"solar_nips\": {\"num_feat_dynamic_real\": 4},\n",
    "    \"electricity_nips\": {\"num_feat_dynamic_real\": 4},\n",
    "    \"traffic_nips\": {\"num_feat_dynamic_real\": 4},\n",
    "    \"taxi_30min\": {\"num_feat_dynamic_real\": 6},\n",
    "    \"wiki-rolling_nips\": {\"num_feat_dynamic_real\": 2},\n",
    "}\n",
    "\n",
    "n_hyp = 8\n",
    "fast_dev_run = True\n",
    "device = \"cpu\" if not torch.cuda.is_available() else \"gpu\"\n",
    "max_target_dim = min(2000, int(metadata.feat_static_cat[0].cardinality))\n",
    "train_grouper = MultivariateGrouper(max_target_dim=max_target_dim)\n",
    "test_grouper = MultivariateGrouper(num_test_dates=int(len(dataset.test)/len(dataset.train)), \n",
    "                                max_target_dim=max_target_dim)\n",
    "dataset_train = train_grouper(dataset.train)\n",
    "dataset_test = test_grouper(dataset.test)\n",
    "\n",
    "# timeMCL configuration\n",
    "\n",
    "model_params = {\n",
    "  'beta': 1.0,\n",
    "  'num_hypotheses': 4,\n",
    "  'mcl_hidden_dim': 300,\n",
    "  'num_layers': 2,\n",
    "  'num_cells': 40,\n",
    "  'cell_type': \"LSTM\",\n",
    "  'num_parallel_samples': 100,\n",
    "  'dropout_rate': 0.1,\n",
    "  'embedding_dimension': 0,\n",
    "  'conditioning_length': 100,\n",
    "  'loss_type': \"l2\",\n",
    "  'residual_layers': 8,\n",
    "  'residual_channels': 8,\n",
    "  'dilation_cycle_length': 2,\n",
    "  'scaling': True,\n",
    "  'pick_incomplete': False,\n",
    "  'time_features': None,\n",
    "  'mcl_loss_type': \"min_ext_sum\", \n",
    "  'num_feat_dynamic_real': datasets_params[dataset_name]['num_feat_dynamic_real'],\n",
    "  'score_loss_weight': 0.5,\n",
    "  'wta_mode': \"relaxed-wta\",\n",
    "  'wta_mode_params': {\n",
    "    'epsilon': 0.1,\n",
    "    'temperature_ini': 10,\n",
    "    'temperature': 10,\n",
    "    'scheduler_mode': \"exponential\",\n",
    "    'temperature_decay': 0.95,\n",
    "    'temperature_lim': 5e-4,\n",
    "    'wta_after_temperature_lim': True},\n",
    "  'optim_kwargs':{\n",
    "    'lr': 1e-3,\n",
    "    'weight_decay': 1e-8,\n",
    "    'patience': 10,\n",
    "  },\n",
    "  'sample_hyps': True,\n",
    "  'single_linear_layer': True,\n",
    "  'backbone_deleted': True,\n",
    "  'scaler_type': \"mean\",\n",
    "  'div_by_std': False,\n",
    "  'minimum_std': 1e-3,\n",
    "  'minimum_std_cst': 1e-4,\n",
    "  'default_scale': False,\n",
    "  'default_scale_cst': False,\n",
    "  'add_minimum_std': False,\n",
    "  }\n",
    "\n",
    "trainer_kwargs = {\n",
    "    'max_epochs': 5 if fast_dev_run else 200,\n",
    "    'accelerator': device,\n",
    "    'gradient_clip_val': 10.0,\n",
    "    'validation_only': False,\n",
    "}\n",
    "\n",
    "data_kwargs = {\n",
    "    'num_batches_per_epoch': 30,\n",
    "    'num_batches_val_per_epoch': 100,\n",
    "    'batch_size': 200,\n",
    "    'shuffle_buffer_length': None,\n",
    "    'train': {\n",
    "    'type': \"Gluonts_ds\",\n",
    "    'split_train_val': True,\n",
    "    'n_pred_steps_val': 10, # number of step of validation (as a factor of the prediction length)\n",
    "    'dataset_name': dataset_name,\n",
    "    'num_feat_dynamic_real': datasets_params[dataset_name]['num_feat_dynamic_real']},\n",
    "    'eval' : {\n",
    "    'type': \"Gluonts_ds\",\n",
    "    'dataset_name': \"solar_nips\",\n",
    "    'num_feat_dynamic_real': datasets_params[dataset_name]['num_feat_dynamic_real']},\n",
    "    }\n",
    "\n",
    "estimator = timeMCL_estimator(\n",
    "            freq=metadata.freq,\n",
    "            prediction_length=metadata.prediction_length,\n",
    "            target_dim=max_target_dim,\n",
    "            context_length=metadata.prediction_length,\n",
    "            trainer_kwargs=trainer_kwargs,\n",
    "            data_kwargs=data_kwargs,\n",
    "            **model_params,\n",
    "        )\n",
    "\n",
    "predictor = estimator.train(dataset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run the following commands for inference and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_it, ts_it = make_evaluation_predictions(\n",
    "    dataset=dataset_test, \n",
    "    predictor=predictor, \n",
    "    num_samples=n_hyp\n",
    ")\n",
    "forecasts = list(forecast_it)\n",
    "targets = list(ts_it)\n",
    "\n",
    "evaluator = MultivariateEvaluator(quantiles=(np.arange(20)/20.0)[1:],\n",
    "                                target_agg_funcs={'sum': np.sum})\n",
    "\n",
    "agg_metric, _, distorsion = evaluator(\n",
    "                targets, forecasts, num_series=len(dataset_test)\n",
    "            )\n",
    "            \n",
    "agg_metric[\"Distorsion\"] = distorsion\n",
    "\n",
    "print(\"RMSE: {}\".format(agg_metric[\"m_sum_RMSE\"]))\n",
    "print(\"Distorsion: {}\".format(agg_metric[\"Distorsion\"]))\n",
    "print(\"CRPS-Sum: {}\".format(agg_metric[\"m_sum_mean_wQuantileLoss\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_path = \"tmcl_example_{}.png\".format(dataset_name)\n",
    "\n",
    "# Formatting first window forecasts & observations\n",
    "hypothesis_forecasts = forecasts[0].samples  # shape (N, forecast_length, target_dim)\n",
    "target_df = targets[0]\n",
    "\n",
    "# plot tMCL forecasts\n",
    "plot_mcl(\n",
    "        target_df=target_df,\n",
    "        hypothesis_forecasts=hypothesis_forecasts,\n",
    "        forecast_length=metadata.prediction_length,\n",
    "        context_points=metadata.prediction_length,\n",
    "        rows=3,\n",
    "        cols=2,\n",
    "        plot_mean=True,\n",
    "        freq_type=metadata.freq,\n",
    "        fname=figure_path,\n",
    "        is_mcl=True,  \n",
    "        extract_unique=True  \n",
    ")\n",
    "\n",
    "print('Figure saved in {}'.format(figure_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "time_series",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
